data_dir: ./data/NYCtaxi  # Directory where your data files are stored
model_dir: ./saved_models  # Directory to save trained models
checkpoint_dir: ./checkpoints  # Directory to save model checkpoints
num_nodes: 265  # Number of nodes (or features) in your data
batch_size: 256  # Batchsize for training
num_epochs: 100  # Number of training epochs
learning_rate: 0.005  # Learning rate for the optimizer
log_dir : ./logs/nyc_taxi
feature_dim: 2
dropout: 0.3
blocks: 4
layers: 2
gcn_bool: True
addaptadj: True
randomadj: True
aptonly: True
kernel_size: 2
nhid: 32
residual_channels: 32
dilation_channels: 32
skip_channels: 256
end_channels: 512
input_window: 6
output_window: 1
output_dim: 2
device: cuda  # Use 'cuda' for GPU or 'cpu' for CPU
train_months: 12
val_last_days : 15
test_year : 2022
test_month : 12
adj_mx_file : adjacency_matrix.npy
model : GWNET
# Learning rate scheduler configuration
lr_scheduler:
  type: plateau  # Type of learning rate scheduler (step or plateau)
  step_size: 2  # Step size for learning rate decay (used when type is 'step')
  gamma: 0.9  # Multiplicative factor for learning rate decay (used when type is 'step')
  factor: 0.5  # Factor by which the learning rate will be reduced (used when type is 'plateau')
  patience: 5  # Number of epochs with no improvement after which learning rate will be reduced (used when type is 'plateau')
train_method: 'weighted'
warm_up_day_num : 730
alpha : 0.9  ##alpha in ema
alpha2 : 1  ##alpha in self_kd_loss
dataset_name : nyc_taxi
